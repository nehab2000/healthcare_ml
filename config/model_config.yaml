model:
  # CNN Model Settings
  cnn:
    architecture: "resnet50"  # Options: resnet50, resnet101, densenet121, efficientnet_b3
    pretrained: true
    num_classes: 2
    dropout_rate: 0.5
    
  # Vision Transformer Settings
  vit:
    model_name: "google/vit-base-patch16-224"  # HuggingFace model name
    pretrained: true
    num_classes: 2
    image_size: 224
    patch_size: 16
    dropout_rate: 0.5
  
  # Training Hyperparameters
  training:
    batch_size: 32
    num_epochs: 50
    learning_rate: 1e-4
    weight_decay: 1e-4
    optimizer: "adamw"  # Options: adamw, sgd
    scheduler: "cosine"  # Options: cosine, reduce_on_plateau, step
    early_stopping:
      patience: 10
      min_delta: 0.001
      monitor: "val_loss"
    mixed_precision: true  # Use FP16 training
    
    # Learning rate scheduler specific settings
    cosine_annealing:
      T_max: 50
      eta_min: 1e-6
    
    reduce_on_plateau:
      factor: 0.5
      patience: 5
      min_lr: 1e-7
    
    step_lr:
      step_size: 10
      gamma: 0.1
  
  # Loss function
  loss:
    type: "cross_entropy"  # Options: cross_entropy, focal_loss
    class_weights: null  # null for balanced, or [weight_normal, weight_pneumonia]
    focal_alpha: 0.25
    focal_gamma: 2.0
  
  # Data Augmentation
  augmentation:
    train:
      horizontal_flip: true
      rotation: 15  # degrees
      brightness: 0.2  # factor
      contrast: 0.2  # factor
      scale: [0.9, 1.1]  # random scaling
    val:
      # Minimal augmentation for validation
      horizontal_flip: false
      rotation: 0
      brightness: 0.0
      contrast: 0.0
  
  # Model Checkpointing
  checkpoint:
    save_dir: "checkpoints"
    save_best: true
    save_last: true
    monitor_metric: "val_accuracy"  # Options: val_accuracy, val_loss, val_f1
  
  # Logging
  logging:
    use_tensorboard: true
    log_dir: "logs"
    log_interval: 10  # Log every N batches


